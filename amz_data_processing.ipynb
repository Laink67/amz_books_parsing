{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F \n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"rs\"\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(APP_NAME)\\\n",
    "    .master(\"local[3]\")\\\n",
    "    .config('spark.ui.port', \"4040\")\\\n",
    "    .config(\"spark.driver.memory\", \"2g\")\\\n",
    "    .config(\"spark.executor.memory\", \"3g\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154583, 9)\n"
     ]
    }
   ],
   "source": [
    "domen = 'com'\n",
    "cur_pd_books = pd.read_csv(f'new_{domen}_books_0_1056.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_items = pd.read_csv('new_book_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, LongType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"asin\",LongType(),True), \\\n",
    "    StructField(\"reviewerID\", StringType(),True), \\\n",
    "    StructField(\"reviewerName\", StringType(), True), \\\n",
    "    StructField(\"overall\", DoubleType(), True), \\\n",
    "    StructField(\"unixReviewTime\", StringType(), True), \\\n",
    "    StructField(\"style\", StringType(), True), \\\n",
    "    StructField(\"summary\", StringType(), True), \\\n",
    "    StructField(\"reviewText\", StringType(), True), \\\n",
    "    StructField(\"verified\", StringType(), True)           \n",
    "  ])\n",
    "\n",
    "books_ = spark.createDataFrame(cur_pd_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete beginning word 'book'. It was necessary for searching\n",
    "books = books.withColumn('asin', F.regexp_replace('asin', r\"^book \", ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reviewerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve text between ''\n",
    "books = books.withColumn('reviewerID', F.regexp_extract(books.reviewerID, r\"\\'([^\\'\\']+)\\'\", 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriev text between '.\n",
    "books = books.withColumn('overall', F.regexp_extract(books.rating, r\"\\'[^\\'\\']+\\.\", 0))\n",
    "# delete extra characters '.\n",
    "books = books.withColumn('overall', F.regexp_replace('overall', r\"'|\\.\", ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve text between ''\n",
    "books = books.withColumn('summary', F.regexp_extract(books.summary, r\"\\'([^\\'\\']+)\\'\", 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body\n",
    "\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecesary beginning\n",
    "books = books.withColumn('reviewText', F.regexp_replace('reviewText', r\"\\'(\\\\n|\\s)*'\", ''))\n",
    "# retrieve text between []\n",
    "books = books.withColumn('reviewText', F.regexp_extract(books.reviewText, r\"\\[([^\\[\\]]+)\\]\", 1))\n",
    "# Delete signs: , '\n",
    "books = books.withColumn('reviewText', F.regexp_replace('reviewText', r\"(\\',)|(, \\')\", ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve text between ''\n",
    "books = books.withColumn('unixReviewTime', F.regexp_extract(books.date, r\"\\'([^\\'\\']+)\\'\", 1))\n",
    "books = books.select('unixReviewTime').persist(StorageLevle.DISK_ONLY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
